{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHs4kEaRGycL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1:  What is Logistic Regression, and how does it differ from Linear Regression?\n",
        "- Logistic regression and linear regression are both used for prediction.\n",
        "- logistic regression predicts a categorical outcome while linear regression predicts a continuous numerical outcome\n",
        "\n",
        "Question 2: Explain the role of the Sigmoid function in Logistic Regression.\n",
        "- The sigmoid function transforms a model's raw, unbounded output into a probability between 0 and 1, enabling binary classification by mapping this probability to discrete outcomes (0 or 1).\n",
        "\n",
        "Question 3: What is Regularization in Logistic Regression and why is it needed?\n",
        "- a technique that prevents overfitting by adding a penalty term to the loss function, which shrinks model coefficients and reduces complexity\n",
        "\n",
        "Question 4: What are some common evaluation metrics for classification models, and why are they important?\n",
        "- Accuracy, Precision, Recall (Sensitivity), Specificity, F1-Score, and AUC-ROC\n",
        "-\n",
        "\n"
      ],
      "metadata": {
        "id": "5zEaWYqZG4Cn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 5: Write a Python program that loads a CSV file into a Pandas DataFrame, splits into train/test sets,\n",
        "#trains a Logistic Regression model, and prints its accuracy.\n",
        "#(Use Dataset from sklearn package) (Include your Python code and output in the code box below.)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "data = load_iris()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state= 1)\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "KtAKkskAHHAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43d7925e-87a5-4931-fa44-fc7bd134ffe0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 6:  Write a Python program to train a Logistic Regression model using L2 regularization (Ridge) and print the model coefficients and accuracy.\n",
        " #(Use Dataset from sklearn package) (Include your Python code and output in the code box below.)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "data = load_iris()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state= 1)\n",
        "model = LogisticRegression(penalty='l2', C=1.0)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(model.coef_)"
      ],
      "metadata": {
        "id": "rVDkleVuHL8L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16807ef6-9f97-4462-955c-9100f8cf7b0f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9666666666666667\n",
            "[[-0.43171259  0.82344651 -2.35119244 -0.96938012]\n",
            " [ 0.61818491 -0.42815386 -0.20595953 -0.82952283]\n",
            " [-0.18647232 -0.39529265  2.55715197  1.79890295]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 7: Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr' and print the classification report.\n",
        " #(Use Dataset from sklearn package) (Include your Python code and output in the code box below.)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import classification_report\n",
        "X,y =  make_classification(n_samples=1000, n_features=10, n_redundant=5, n_informative=5, n_classes=3, random_state=1)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state=1)\n",
        "model = LogisticRegression(multi_class='ovr')\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "Nfg3AN06HSgJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4e97782-c005-4f2c-db9d-ac03dedabf04"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.76      0.72        99\n",
            "           1       0.62      0.65      0.64        89\n",
            "           2       0.76      0.67      0.71       112\n",
            "\n",
            "    accuracy                           0.69       300\n",
            "   macro avg       0.69      0.69      0.69       300\n",
            "weighted avg       0.70      0.69      0.69       300\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 8: Write a Python program to apply GridSearchCV to tune C and penalty hyperparameters for Logistic Regression and print the best parameters and validation accuracy.\n",
        " #(Use Dataset from sklearn package) (Include your Python code and output in the code box below.)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "logistic_regression = LogisticRegression(solver='liblinear', max_iter=1000)\n",
        "param_grid = {\n",
        "    'C': np.logspace(-4, 4, 10),\n",
        "    'penalty': ['l1', 'l2']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=logistic_regression, param_grid=param_grid, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best validation accuracy: {grid_search.best_score_:.4f}\")\n",
        "best_model = grid_search.best_estimator_\n",
        "test_accuracy = best_model.score(X_test, y_test)\n",
        "print(f\"Test set accuracy with best parameters: {test_accuracy:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "fut0U-nrHXyx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abbfce7b-3787-416d-932a-bbd965385ec1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "Best parameters: {'C': np.float64(1291.5496650148827), 'penalty': 'l2'}\n",
            "Best validation accuracy: 0.9626\n",
            "Test set accuracy with best parameters: 0.9561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 9: Write a Python program to standardize the features before training Logistic Regression and compare the model's accuracy with and without scaling.\n",
        " #(Use Dataset from sklearn package) (Include your Python code and output in the code box below.)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "data = load_iris()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state= 1)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy without scaling: {accuracy}\")\n",
        "model_scaled = LogisticRegression()\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "print(f\"Accuracy with scaling: {accuracy_scaled}\")"
      ],
      "metadata": {
        "id": "ykeepQXWHdSL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2410d97-fdaf-47f9-e45a-0162275dbc42"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without scaling: 0.9666666666666667\n",
            "Accuracy with scaling: 0.9666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 10: Imagine you are working at an e-commerce company that wants to predict which customers will respond to a marketing campaign.\n",
        "#Given an imbalanced dataset (only 5% of customers respond), describe the approach you’d take to build a Logistic Regression model —\n",
        "#including data handling, feature scaling, balancing classes, hyperparameter tuning, and evaluating the model for this real-world business use case.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# 1. Simulate an imbalanced dataset\n",
        "# In a real scenario, you would load your data from a CSV, database, etc.\n",
        "np.random.seed(42)\n",
        "n_samples = 1000\n",
        "n_features = 10\n",
        "\n",
        "# Generate features\n",
        "X = np.random.rand(n_samples, n_features) * 10\n",
        "\n",
        "# Generate target with 5% positive class\n",
        "y = np.zeros(n_samples)\n",
        "positive_indices = np.random.choice(n_samples, int(n_samples * 0.05), replace=False)\n",
        "y[positive_indices] = 1\n",
        "\n",
        "# Convert to DataFrame for easier handling\n",
        "df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(n_features)])\n",
        "df['target'] = y\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# 2. Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# 3. Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 4. Balancing Classes using SMOTE (Synthetic Minority Over-sampling Technique)\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "print(f\"Original training class distribution: {np.bincount(y_train.astype(int))}\")\n",
        "print(f\"Resampled training class distribution: {np.bincount(y_train_resampled.astype(int))}\")\n",
        "\n",
        "# 5. Hyperparameter Tuning for Logistic Regression\n",
        "# Define the parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # Inverse of regularization strength\n",
        "    'solver': ['liblinear', 'lbfgs'], # Algorithm to use in the optimization problem\n",
        "    'class_weight': [None, 'balanced'] # Handle class imbalance by adjusting weights\n",
        "}\n",
        "\n",
        "# Initialize Logistic Regression model\n",
        "log_reg = LogisticRegression(random_state=42, max_iter=1000)\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(log_reg, param_grid, cv=5, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
        "\n",
        "# Fit GridSearchCV on the resampled training data\n",
        "grid_search.fit(X_train_resampled, y_train_resampled)\n",
        "\n",
        "# Get the best estimator\n",
        "best_log_reg = grid_search.best_estimator_\n",
        "\n",
        "print(f\"\\nBest hyperparameters: {grid_search.best_params_}\")\n",
        "\n",
        "# 6. Model Training and Evaluation\n",
        "# Make predictions on the scaled test set using the best model\n",
        "y_pred = best_log_reg.predict(X_test_scaled)\n",
        "y_pred_proba = best_log_reg.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(f\"ROC AUC Score: {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "FTQ0L1yaHjSQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6b83122-e256-4b67-e62b-eafe4141703b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original training class distribution: [760  40]\n",
            "Resampled training class distribution: [760 760]\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "\n",
            "Best hyperparameters: {'C': 10, 'class_weight': None, 'solver': 'lbfgs'}\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.93      0.55      0.69       190\n",
            "         1.0       0.02      0.20      0.04        10\n",
            "\n",
            "    accuracy                           0.54       200\n",
            "   macro avg       0.48      0.38      0.37       200\n",
            "weighted avg       0.88      0.54      0.66       200\n",
            "\n",
            "ROC AUC Score: 0.3263\n",
            "\n",
            "Confusion Matrix:\n",
            "[[105  85]\n",
            " [  8   2]]\n"
          ]
        }
      ]
    }
  ]
}